{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5pLH29lj_f8-"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import os,glob,pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndAHJewP_wh2",
        "outputId": "de78ad65-b8ee-473e-b3cf-a8770fcb494d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e-GsdHKk_f9B"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install audiomentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO9iQVm8ACrI",
        "outputId": "f2ef16d8-47b9-40a1-9b63-f15669407268"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.26.0-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.21.6)\n",
            "Requirement already satisfied: librosa<0.10.0,>0.7.2 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (0.8.1)\n",
            "Requirement already satisfied: scipy<2,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.7.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.56.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.4.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (3.0.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.1.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.10.3.post1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (21.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (0.39.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (4.12.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<0.10.0,>0.7.2->audiomentations) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (2.21)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (3.8.1)\n",
            "Installing collected packages: audiomentations\n",
            "Successfully installed audiomentations-0.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jBCUV3OD_f9C"
      },
      "outputs": [],
      "source": [
        "from audiomentations import Compose, AddGaussianNoise, PitchShift, HighPassFilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ctVdRQ-t_f9C"
      },
      "outputs": [],
      "source": [
        "def featureExtractor(audio):\n",
        "    librosa_audio_data, librosa_sample_rate=librosa.load(audio)\n",
        "    mfccs_features= librosa.feature.mfcc(y=librosa_audio_data, sr= librosa_sample_rate,n_mfcc=50)\n",
        "    ar=np.resize(feature,(50,280))\n",
        "    ar = np.expand_dims(ar, axis=-1)\n",
        "#     mfccs_features=mfccs_features.reshape(50,280)\n",
        "#     print(librosa_sample_rate)\n",
        "    return ar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yW0VwWPy_f9D"
      },
      "outputs": [],
      "source": [
        "def featureExtractor2(audio,sr):\n",
        "    mfccs_features= librosa.feature.mfcc(y=audio, sr= sr,n_mfcc=50)\n",
        "    return mfccs_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kT5AE4uR_f9D"
      },
      "outputs": [],
      "source": [
        "x=[]\n",
        "y=[]\n",
        "def load_data():\n",
        "    for file in glob.glob(r\"/content/drive/MyDrive/Baby_audio_dataset/*\"):\n",
        "        label = os.path.basename(file)\n",
        "        for audio in glob.glob(file+\"/*.wav\"):\n",
        "            x.append(audio)\n",
        "            if label!='hungry':\n",
        "                label='nonHungry'\n",
        "            y.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7T38ZXrF_f9E",
        "outputId": "025c2c42-ab2b-4f0a-9131-c005db309700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "633 633\n"
          ]
        }
      ],
      "source": [
        "load_data()\n",
        "print(len(x),len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dttX0Dy6_f9G"
      },
      "outputs": [],
      "source": [
        "def shift_time(data, sampling_rate, shift_max, shift_direction):\n",
        "    shift = np.random.randint(sampling_rate * shift_max)\n",
        "    if shift_direction == 'right':\n",
        "        shift = -shift\n",
        "    elif shift_direction == 'both':\n",
        "        direction = np.random.randint(0, 2)\n",
        "        if direction == 1:\n",
        "            shift = -shift\n",
        "    augmented_data = np.roll(data, shift)\n",
        "    # Set to silence for heading/ tailing\n",
        "    if shift > 0:\n",
        "        augmented_data[:shift] = 0\n",
        "    else:\n",
        "        augmented_data[shift:] = 0\n",
        "    return augmented_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FddAsmbQ_f9G"
      },
      "outputs": [],
      "source": [
        "def time_stretch(signal, time_stretch_rate):\n",
        "    return librosa.effects.time_stretch(signal, time_stretch_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z4vzzedZ_f9H"
      },
      "outputs": [],
      "source": [
        "def pitch_scale(signal, sr, num_semitones):\n",
        "    return librosa.effects.pitch_shift(signal, sr, num_semitones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6pwEV8Kb_f9I"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def random_gain(signal, min_factor=0.1, max_factor=0.12):\n",
        "    gain_rate = random.uniform(min_factor, max_factor)\n",
        "    augmented_signal = signal * gain_rate\n",
        "    return augmented_signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PbwY4a4R_f9I"
      },
      "outputs": [],
      "source": [
        "# Raw audio augmentation\n",
        "augment_raw_audio = Compose(\n",
        "    [\n",
        "        AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.2, p=1),\n",
        "        PitchShift(min_semitones=-8, max_semitones=8, p=1),\n",
        "        HighPassFilter(min_cutoff_freq=2000, max_cutoff_freq=4000, p=1)\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3PszqgA6_f9J"
      },
      "outputs": [],
      "source": [
        "aug_data=[]\n",
        "aug_label=[]\n",
        "i=0\n",
        "for audio,label in zip(x,y):\n",
        "    if label != 'hungry':\n",
        "        signal,sr=librosa.load(audio)\n",
        "        augmented_signal1=shift_time(signal,sr,2,'both')\n",
        "        augmented_signal2=time_stretch(signal,0.5)\n",
        "        augmented_signal3=pitch_scale(signal,sr,2)\n",
        "#         augmented_signal4=shift_time(signal,sr,3,'right')\n",
        "        augmented_signal5=random_gain(signal,2,4)\n",
        "        augmented_signal6=augment_raw_audio(signal,sr)\n",
        "        \n",
        "        aug_data.append((augmented_signal1,sr))\n",
        "        aug_label.append(label)\n",
        "        aug_data.append((augmented_signal2,sr))\n",
        "        aug_label.append(label)\n",
        "        aug_data.append((augmented_signal3,sr))\n",
        "#         aug_label.append(label)\n",
        "#         aug_data.append((augmented_signal4,sr))\n",
        "        aug_label.append(label)\n",
        "        aug_data.append((augmented_signal5,sr))\n",
        "        aug_label.append(label)\n",
        "        aug_data.append((augmented_signal6,sr))\n",
        "        aug_label.append(label)\n",
        "#         sf.write(\"augmented_signal1.wav\", augmented_signal, sr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZYWbJsS1_f9J"
      },
      "outputs": [],
      "source": [
        "extracted_features=[]\n",
        "\n",
        "def extractFeatures(X,Y):\n",
        "    x=[]\n",
        "    y=[]\n",
        "    for audio,label in zip(X,Y):\n",
        "        signal,sr=librosa.load(audio)\n",
        "        feature = featureExtractor2(signal,sr)\n",
        "        ar=np.resize(feature,(50,280))\n",
        "        x.append(ar)\n",
        "        y.append(label)\n",
        "        extracted_features.append([feature,label])\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fLuudmgF_f9K"
      },
      "outputs": [],
      "source": [
        "X,Y=extractFeatures(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TQN7U78z_f9K"
      },
      "outputs": [],
      "source": [
        "def extractFeatures2(X,Y):\n",
        "    x=[]\n",
        "    y=[]\n",
        "    for audio,label in zip(X,Y):\n",
        "        singal=audio[0]\n",
        "        sr=audio[1]\n",
        "        feature = featureExtractor2(signal,sr)\n",
        "        ar=np.resize(feature,(50,280))\n",
        "        x.append(ar)\n",
        "        y.append(label)\n",
        "        extracted_features.append([feature,label])\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Por2ZhNc_f9L"
      },
      "outputs": [],
      "source": [
        "augX,augY=extractFeatures2(aug_data,aug_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9MRpEg_T_f9M"
      },
      "outputs": [],
      "source": [
        "for feature,label in zip(augX,augY):\n",
        "    X.append(feature)\n",
        "    Y.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "40RV5z24_f9M",
        "outputId": "8667139c-5d77-4cb1-82bf-2347c1dbfeaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1888 1888\n"
          ]
        }
      ],
      "source": [
        "print(len(X),len(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9EQL8pyT_f9N",
        "outputId": "c3fe096e-64b4-4c84-ccb0-e40506ba9677",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1510 1510 378 378\n"
          ]
        }
      ],
      "source": [
        "#train test split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n",
        "print(len(X_train),len(y_train),len(X_test),len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "JQ1d2wpn_f9N",
        "outputId": "dafc4dc2-8e48-4e35-db3b-cace70246fab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1510, 50, 280)\n",
            "(1510,)\n"
          ]
        }
      ],
      "source": [
        "length=len(X_train)\n",
        "X_train=np.array(X_train).reshape(length,50,280)\n",
        "y_train=np.array(y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6MKk_2lf_f9O",
        "outputId": "17e8bd3c-f0e7-440c-edef-a9634dc1bce4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1510, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y_train=to_categorical(labelencoder.fit_transform(y_train))\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SS-AoZYN_f9O",
        "outputId": "612b439b-8273-43d3-e0c1-0644f5e644e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(378, 50, 280)\n",
            "(378,)\n"
          ]
        }
      ],
      "source": [
        "length=len(X_test)\n",
        "X_test=np.array(X_test).reshape(length,50,280)\n",
        "y_test=np.array(y_test)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tR9_tzIH_f9P",
        "outputId": "1a02840a-ad2d-4191-dd7c-e4a557ec9c54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(378, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y_test=to_categorical(labelencoder.fit_transform(y_test))\n",
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "L1tQvzN8_f9Q",
        "outputId": "0dccc6c9-116a-46aa-d748-94d2b8f8da45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1510, 50, 280, 1) (378, 50, 280, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "print(X_train.shape,X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CvFtziiS_f9Q",
        "outputId": "202e5c6c-da83-4dc7-ed8c-74b8f5813b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 48, 278, 32)       320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 24, 139, 32)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 24, 139, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 137, 32)       9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 69, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 11, 69, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 68, 32)        4128      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 34, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 5, 34, 32)        128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5440)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                87056     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,170\n",
            "Trainable params: 100,978\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# BUILDING MODEL\n",
        "\n",
        "import tensorflow as tf\n",
        "# print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras as keras\n",
        "from sklearn import metrics\n",
        "\n",
        "# num_labels=y.shape[1]\n",
        "\n",
        "def build_model(input_shape):\n",
        "    model=Sequential()\n",
        "    # 1st conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu',input_shape=input_shape))\n",
        "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPool2D((3,3), strides=(2,2),padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 3rd conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (2,2), activation='relu'))\n",
        "    model.add(keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # flatten into 1D array\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(16,activation='relu'))\n",
        "#     model.add(keras.layers.Dense(32,activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(2))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    return model\n",
        "\n",
        "input_shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
        "model=build_model(input_shape)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BmZnJ9C4_f9R"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "# def f1_m(y_true, y_pred):\n",
        "#     precision = precision_m(y_true, y_pred)\n",
        "#     recall = recall_m(y_true, y_pred)\n",
        "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "99eTLPI__f9R",
        "outputId": "fb71b10d-b743-405a-c646-a002228f8c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "48/48 [==============================] - 18s 357ms/step - loss: 0.1772 - acc: 0.9338 - val_loss: 0.2743 - val_acc: 0.8069\n",
            "Epoch 2/13\n",
            "48/48 [==============================] - 17s 354ms/step - loss: 0.1201 - acc: 0.9424 - val_loss: 0.1583 - val_acc: 0.9444\n",
            "Epoch 3/13\n",
            "48/48 [==============================] - 17s 354ms/step - loss: 0.1098 - acc: 0.9583 - val_loss: 0.1596 - val_acc: 0.9312\n",
            "Epoch 4/13\n",
            "48/48 [==============================] - 17s 355ms/step - loss: 0.0789 - acc: 0.9702 - val_loss: 0.1371 - val_acc: 0.9497\n",
            "Epoch 5/13\n",
            "48/48 [==============================] - 17s 355ms/step - loss: 0.0620 - acc: 0.9755 - val_loss: 0.1294 - val_acc: 0.9550\n",
            "Epoch 6/13\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0480 - acc: 0.9748 - val_loss: 0.1495 - val_acc: 0.9497\n",
            "Epoch 7/13\n",
            "48/48 [==============================] - 17s 361ms/step - loss: 0.0667 - acc: 0.9775 - val_loss: 0.1506 - val_acc: 0.9471\n",
            "Epoch 8/13\n",
            "48/48 [==============================] - 17s 361ms/step - loss: 0.0445 - acc: 0.9815 - val_loss: 0.2306 - val_acc: 0.9259\n",
            "Epoch 9/13\n",
            "48/48 [==============================] - 17s 359ms/step - loss: 0.0293 - acc: 0.9901 - val_loss: 0.1814 - val_acc: 0.9312\n",
            "Epoch 10/13\n",
            "48/48 [==============================] - 17s 357ms/step - loss: 0.0148 - acc: 0.9954 - val_loss: 0.2270 - val_acc: 0.9418\n",
            "Epoch 11/13\n",
            "48/48 [==============================] - 17s 359ms/step - loss: 0.0208 - acc: 0.9907 - val_loss: 0.3038 - val_acc: 0.9497\n",
            "Epoch 12/13\n",
            "48/48 [==============================] - 17s 358ms/step - loss: 0.0211 - acc: 0.9934 - val_loss: 0.2516 - val_acc: 0.9524\n",
            "Epoch 13/13\n",
            "48/48 [==============================] - 17s 357ms/step - loss: 0.0112 - acc: 0.9960 - val_loss: 0.2766 - val_acc: 0.9524\n",
            "Training completed in time:  0:04:22.746274\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
        "# model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "start=datetime.now()\n",
        "# history = model.fit(x_train, y_train, validation_split=0.3, epochs=10, verbose=0)\n",
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=32,epochs=13)\n",
        "\n",
        "duration=datetime.now() - start\n",
        "print(\"Training completed in time: \",duration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_61hiSUZ_f9S",
        "outputId": "731cef55-d95f-48e3-a161-6653f1ef4e96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  0.27663788199424744\n",
            "accuracy:  0.9523809552192688\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy= model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"loss: \",loss)\n",
        "print(\"accuracy: \",accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "s2e8h5fE_f9S",
        "outputId": "5121a15b-113f-4b3f-ef1a-33b529c22679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 77   1]\n",
            " [ 17 283]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test) \n",
        "y_pred = np.argmax(y_pred, axis = 1) \n",
        "label = np.argmax(y_test,axis = 1) \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(label,y_pred))\n",
        "# print(\"y_test:\\n\", label)\n",
        "# print(\"y_pred:\\n\",y_pred) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "MjBp7V9u_f9T"
      },
      "outputs": [],
      "source": [
        "model.save('models/model1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qW6iSJWc_f9T"
      },
      "outputs": [],
      "source": [
        "cnn1 = tf.keras.models.load_model(\"models/model1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Ox7zNist_f9T",
        "outputId": "27d94314-6021-4a5a-9cad-8838f6df269c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.99      0.90        78\n",
            "           1       1.00      0.94      0.97       300\n",
            "\n",
            "    accuracy                           0.95       378\n",
            "   macro avg       0.91      0.97      0.93       378\n",
            "weighted avg       0.96      0.95      0.95       378\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,f1_score\n",
        "print(classification_report(y_true=label,y_pred=y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "P_UmoW46_f9U",
        "outputId": "edf3b722-1db2-4454-bf9e-da86f6fab305",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The f1-score per class:  [0.89534884 0.96917808]\n",
            "The f1-score :  0.9539434760842852\n"
          ]
        }
      ],
      "source": [
        "f1_score_per_class_validation = f1_score(y_true=label,y_pred=y_pred,average=None) \n",
        "print(\"The f1-score per class: \",f1_score_per_class_validation)\n",
        "print(\"The f1-score : \",f1_score(y_true=label,y_pred=y_pred,average='weighted'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRuifuN1_f9U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}